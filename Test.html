import os
import re
import shutil
import glob

def get_original_filename(filename):
    """
    Remove any known prefixes and unwanted words/characters from the filename.
    """
    prefixes = [
        "Script Error ",
        "Unpingable ",
        "Routes - IPv6 Pinged - ",
        "Routes - IPv6 Unreached - ",
        "Ping Check - ",
        "Region_IP_Mismatch ",
        "Region_IP_"
    ]
    for prefix in prefixes:
        if filename.startswith(prefix):
            filename = filename[len(prefix):]
    # Remove "Mismatch" regardless of boundaries (case-insensitive)
    filename = re.sub(r'(?i)mismatch', '', filename)
    # Remove whole words "Region" and "IP" (case-insensitive)
    filename = re.sub(r'\b(?:Region|IP)\b', '', filename, flags=re.IGNORECASE)
    # Remove underscores
    filename = filename.replace('_', '')
    # Collapse multiple spaces
    filename = ' '.join(filename.split())
    return filename

def clean_filename(name):
    """
    Remove unwanted words and underscores from the filename.
    """
    # Remove "Mismatch" regardless of boundaries (case-insensitive)
    name = re.sub(r'(?i)mismatch', '', name)
    # Remove whole words "Region" and "IP" (case-insensitive)
    name = re.sub(r'\b(?:Region|IP)\b', '', name, flags=re.IGNORECASE)
    # Remove underscores
    name = name.replace('_', '')
    # Collapse extra whitespace
    name = ' '.join(name.split())
    return name

def process_file(filepath, base_dir):
    # Read the entire file content to process automated output
    with open(filepath, 'r') as file:
        content = file.read()
    
    # Remove error messages using regex for flexible matching.
    content = re.sub(r'stty:\s*standard input:\s*Inappropriate ioctl for device', '\n', content)
    content = re.sub(r'Exit Status:\s*0', '\n', content)

    # Clean up the original file name.
    original_filename = get_original_filename(os.path.basename(filepath))
    
    # --- Automated Commands Output Check ---
    pattern = re.compile(r'AUTOMATED COMMANDS OUTPUT:(.*?)END OF AUTOMATED OUTPUT', re.DOTALL)
    match = pattern.search(content)
    
    if not match:
        target_folder = os.path.join(base_dir, "Scripting Error")
        new_filename = "Script Error " + original_filename
    else:
        section = match.group(1)
        if (section.count("0 packets received") == 2 and section.count("5 packets transmitted") == 2) or \
           (section.count("0 packets received") == 1 and section.count("5 packets transmitted") == 1):
            target_folder = os.path.join(base_dir, "Unpingable")
            new_filename = "Unpingable " + original_filename
        elif section.count("::/0") < 3:
            if section.count("0 packets received") == 0:
                target_folder = os.path.join(base_dir, "Routes Found", "IPv6 Pingable")
                new_filename = "Routes - IPv6 Pinged - " + original_filename
            else:
                target_folder = os.path.join(base_dir, "Routes Found", "IPv6 Not Reachable")
                new_filename = "Routes - IPv6 Unreached - " + original_filename
        elif section.count("0 packets received") == 1:
            target_folder = os.path.join(base_dir, "Clean")
            new_filename = original_filename
        else:
            target_folder = os.path.join(base_dir, "Ping Check")
            new_filename = "Ping Check - " + original_filename

    # Clean the new filename to remove unwanted words/underscores.
    new_filename = clean_filename(new_filename)

    os.makedirs(target_folder, exist_ok=True)
    target_path = os.path.join(target_folder, new_filename)
    
    # Move the file if it isn't already in the target location.
    if os.path.abspath(filepath) != os.path.abspath(target_path):
        shutil.move(filepath, target_path)
        print(f"Moved '{original_filename}' to '{target_folder}' as '{new_filename}'")
        final_path = target_path
    else:
        print(f"'{original_filename}' is already in the correct location.")
        final_path = filepath

    # --- Region Check ---
    # Reopen the file from its final location to check for region mismatch.
    try:
        with open(final_path, 'r') as f:
            file_content = f.read()
        # Find the lines starting with "PE INTERFACE:" and "Region:" (case-insensitive, line by line)
        pe_match = re.search(r'^PE INTERFACE:.*?(\d)\s*$', file_content, re.IGNORECASE | re.MULTILINE)
        region_match = re.search(r'^Region:.*?(\d)\s*$', file_content, re.IGNORECASE | re.MULTILINE)
        if pe_match and region_match:
            pe_digit = pe_match.group(1)
            region_digit = region_match.group(1)
            if pe_digit != region_digit:
                mismatch_folder = os.path.join(base_dir, "Region Mismatch")
                os.makedirs(mismatch_folder, exist_ok=True)
                # Prepend "Region Check " to the file's base name.
                new_name = "Region Check " + os.path.basename(final_path)
                new_mismatch_path = os.path.join(mismatch_folder, new_name)
                shutil.move(final_path, new_mismatch_path)
                print(f"Region mismatch in '{os.path.basename(final_path)}'. Moved to '{mismatch_folder}' as '{new_name}'.")
    except Exception as e:
        print(f"Error during Region check for file {final_path}: {e}")

def generate_report(base_dir):
    """
    Generates a report from files in specific folders:
    
    1. Routes Found -> IPv6 Pingable:
       Checks that the "Scheduler:" line says "Completed". If not, logs "Not Marked as Completed".
    
    2. Clean:
       Checks that files do not have a "Scheduler:" line set to "Completed". If they do, logs "Marked as complete".
    
    3. Scripting Error:
       - If "Error Processing Order" exists, extracts the first {data} and logs "Error with {data}".
       - Otherwise, if there is nothing on the line immediately after "Network Matches:", logs "LASER Match Error".
       - If there is data below "Network Matches:" but the "PE TID:" line is missing or empty, logs "Possible Region Mismatch".
    """
    report_lines = []

    # --- 1. IPv6 Pingable Folder ---
    ipv6_pingable_dir = os.path.join(base_dir, "Routes Found", "IPv6 Pingable")
    if os.path.exists(ipv6_pingable_dir):
        txt_files = glob.glob(os.path.join(ipv6_pingable_dir, '*.txt'))
        for file in txt_files:
            with open(file, 'r') as f:
                content = f.read()
            # Look for the "Scheduler:" line.
            match = re.search(r'^Scheduler:\s*(.*)$', content, flags=re.MULTILINE)
            scheduler_status = match.group(1).strip() if match else ""
            if scheduler_status != "Completed":
                basename = os.path.basename(file)
                report_lines.append(f"{basename}\nNot Marked as Completed\n")
    
    # --- 2. Clean Folder ---
    clean_dir = os.path.join(base_dir, "Clean")
    if os.path.exists(clean_dir):
        txt_files = glob.glob(os.path.join(clean_dir, '*.txt'))
        for file in txt_files:
            with open(file, 'r') as f:
                content = f.read()
            match = re.search(r'^Scheduler:\s*(.*)$', content, flags=re.MULTILINE)
            if match:
                scheduler_status = match.group(1).strip()
                if scheduler_status == "Completed":
                    basename = os.path.basename(file)
                    report_lines.append(f"{basename}\nMarked as complete\n")
    
    # --- 3. Scripting Error Folder ---
    scripting_error_dir = os.path.join(base_dir, "Scripting Error")
    if os.path.exists(scripting_error_dir):
        txt_files = glob.glob(os.path.join(scripting_error_dir, '*.txt'))
        for file in txt_files:
            with open(file, 'r') as f:
                content = f.read()
            basename = os.path.basename(file)
            error_logged = False
            # Check if the file has "Error Processing Order"
            if "Error Processing Order" in content:
                # Extract data within the first pair of curly braces.
                match = re.search(r'\{([^}]+)\}', content)
                if match:
                    data = match.group(1)
                    report_lines.append(f"{basename}\nError with {data}\n")
                    error_logged = True
            if not error_logged:
                # Split into lines to inspect the section below "Network Matches:".
                lines = content.splitlines()
                nm_index = None
                for i, line in enumerate(lines):
                    if line.strip().startswith("Network Matches:"):
                        nm_index = i
                        break
                if nm_index is None or nm_index + 1 >= len(lines) or lines[nm_index + 1].strip() == "":
                    report_lines.append(f"{basename}\nLASER Match Error\n")
                else:
                    # Check for "PE TID:" line.
                    pe_tid_match = re.search(r'^PE TID:\s*(.*)$', content, flags=re.MULTILINE)
                    if not pe_tid_match or pe_tid_match.group(1).strip() == "":
                        report_lines.append(f"{basename}\nPossible Region Mismatch\n")
    
    # --- Write Report ---
    report_path = os.path.join(base_dir, "report.txt")
    with open(report_path, 'w') as report_file:
        for line in report_lines:
            report_file.write(line)
    print(f"Report generated at: {report_path}")

def main():
    # Set your base directory.
    base_dir = r"C:\Users\AD39644\OneDrive - Lumen\Python Version"
    # Recursively find all .txt files in base_dir.
    txt_files = glob.glob(os.path.join(base_dir, '**', '*.txt'), recursive=True)
    for filepath in txt_files:
        process_file(filepath, base_dir)
    
    # Generate report after processing files.
    generate_report(base_dir)

if __name__ == '__main__':
    main()

            
