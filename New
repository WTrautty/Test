def generate_failure_analysis_tab(df):
    import pandas as pd
    import numpy as np
    import plotly.graph_objects as go
    from scipy.stats import chi2_contingency

    SITE_INFO_PATH = r"C:\Path\To\SITE_INFO.xlsx"  # Update to your actual path
    SITE_SHEET = "MAIN"
    required_main_cols = ["LID", "Closure Code 1", "Completed Date", "Create Date"]
    required_site_cols = ["LCK", "Time Zone", "MA", "State", "ST EXLG", "Vendor", "Complex or Simple", "PC/PM"]

    # === Validate main dataset ===
    if not all(col in df.columns for col in required_main_cols):
        return "<div id='failureTab' class='main-tab'><h2>Main dataset missing required columns.</h2></div>"

    # === Read site info ===
    try:
        site_info_df = pd.read_excel(SITE_INFO_PATH, sheet_name=SITE_SHEET, engine="openpyxl")
        print("[DEBUG] SITE_INFO columns:", site_info_df.columns.tolist())
    except Exception as e:
        return f"<div id='failureTab' class='main-tab'><h2>Failed to load SITE_INFO: {e}</h2></div>"

    if not all(col in site_info_df.columns for col in required_site_cols):
        return "<div id='failureTab' class='main-tab'><h2>SITE_INFO missing required columns.</h2></div>"

    # === Preprocess main df ===
    df = df.copy()
    df["Closure Code 1"] = df["Closure Code 1"].fillna("Unknown").astype(str)
    df["Completed Date"] = pd.to_datetime(df["Completed Date"], errors="coerce")
    df["Create Date"] = pd.to_datetime(df["Create Date"], errors="coerce")
    df = df.dropna(subset=["Completed Date", "Create Date", "LID"])
    df["Month"] = df["Completed Date"].dt.to_period("M").astype(str)
    df["LID"] = df["LID"].astype(str)

    # === Preprocess site_info_df ===
    site_info_df = site_info_df[required_site_cols].copy()
    site_info_df["LCK"] = site_info_df["LCK"].astype(str)

    # === Merge datasets ===
    merged = df.merge(site_info_df, how="left", left_on="LID", right_on="LCK")

    # === Run multi-category Cramér's V tests ===
    categorical_vars = ["Time Zone", "MA", "State", "ST EXLG", "Vendor", "Complex or Simple", "PC/PM"]
    cramer_results = []

    for var in categorical_vars:
        if var not in merged.columns:
            continue
        contingency = pd.crosstab(merged[var].fillna("Unknown"), merged["Closure Code 1"])
        if contingency.shape[0] < 2 or contingency.shape[1] < 2:
            continue
        chi2, p, _, _ = chi2_contingency(contingency)
        n = contingency.sum().sum()
        min_dim = min(contingency.shape) - 1
        cramers_v = np.sqrt(chi2 / (n * min_dim)) if min_dim > 0 else 0
        cramer_results.append((var, cramers_v, p))

    if not cramer_results:
        return "<div id='failureTab' class='main-tab'><h2>No valid correlations found with SITE_INFO data.</h2></div>"

    # === Sort and visualize results ===
    cramer_results.sort(key=lambda x: x[1], reverse=True)

    fig = go.Figure()
    for var, v, p in cramer_results:
        if v >= 0.3:
            strength = "Moderate"
        elif v >= 0.1:
            strength = "Weak"
        else:
            strength = "Negligible"
        hovertext = f"{var}<br>Cramér's V = {v:.3f}<br>p = {p:.2e}<br><i>{strength} association</i>"
        fig.add_trace(go.Bar(x=[var], y=[v], text=hovertext, textposition="auto"))

    fig.update_layout(
        title="Correlation Between Closure Code and Site Metadata (Cramér's V)",
        yaxis_title="Cramér's V (0–1)",
        yaxis=dict(range=[0, 1]),
        height=500
    )

    return f"""
    <div id="failureTab" class="main-tab">
      <h2>Failure Analysis</h2>
      <p>This chart shows how strongly site metadata categories relate to different closure codes using Cramér's V.</p>
      {fig.to_html(full_html=False, include_plotlyjs=False)}
    </div>
    """
